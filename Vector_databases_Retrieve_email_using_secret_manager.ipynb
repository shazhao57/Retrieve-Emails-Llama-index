{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shazhao57/Retrieve-Emails-Llama-index/blob/main/Vector_databases_Retrieve_email_using_secret_manager.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yTV6nfrJFiSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc11e410-2281-4bb8-8ed2-21065204b70e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting llama-index\n",
            "  Downloading llama_index-0.6.26-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.2/510.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from llama-index)\n",
            "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
            "Collecting langchain>=0.0.154 (from llama-index)\n",
            "  Downloading langchain-0.0.202-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy>=2.0.15 (from llama-index)\n",
            "  Downloading SQLAlchemy-2.0.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.22.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.2)\n",
            "Collecting openai>=0.26.4 (from llama-index)\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.26.15)\n",
            "Collecting fsspec>=2023.5.0 (from llama-index)\n",
            "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect==0.8.0 (from llama-index)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n",
            "Collecting tiktoken (from llama-index)\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect==0.8.0->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (6.0)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain>=0.0.154->llama-index)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain>=0.0.154->llama-index)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting langchainplus-sdk>=0.0.9 (from langchain>=0.0.154->llama-index)\n",
            "  Downloading langchainplus_sdk-0.0.10-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain>=0.0.154->llama-index)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.154->llama-index) (2.27.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json->llama-index)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json->llama-index)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0.15->llama-index) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2022.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-index) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.154->llama-index)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->llama-index) (23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.154->llama-index) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.154->llama-index) (3.4)\n",
            "Installing collected packages: sqlalchemy, mypy-extensions, multidict, marshmallow, fsspec, frozenlist, async-timeout, yarl, typing-inspect, tiktoken, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, aiosignal, dataclasses-json, aiohttp, openai, langchain, llama-index\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.10\n",
            "    Uninstalling SQLAlchemy-2.0.10:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.4.0\n",
            "    Uninstalling fsspec-2023.4.0:\n",
            "      Successfully uninstalled fsspec-2023.4.0\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.8 frozenlist-1.3.3 fsspec-2023.6.0 langchain-0.0.202 langchainplus-sdk-0.0.10 llama-index-0.6.26 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openai-0.27.8 openapi-schema-pydantic-1.2.4 sqlalchemy-2.0.16 tiktoken-0.4.0 typing-inspect-0.8.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3oxnJk_FjXk",
        "outputId": "b2613fd5-4a10-4292-b078-45afcd3a5a90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JwnRkuPHJ97j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "37751098-64dd-4343-8e98-6923b1fbd25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-secret-manager\n",
            "  Downloading google_cloud_secret_manager-2.16.1-py2.py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-secret-manager) (2.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-secret-manager) (1.22.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-secret-manager) (3.20.3)\n",
            "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-secret-manager)\n",
            "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (2.27.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (1.54.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (4.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-secret-manager) (0.5.0)\n",
            "Installing collected packages: grpc-google-iam-v1, google-cloud-secret-manager\n",
            "Successfully installed google-cloud-secret-manager-2.16.1 grpc-google-iam-v1-0.12.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install google-cloud-secret-manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nTho2vSGKa0y"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d7VEfv71KCeK"
      },
      "outputs": [],
      "source": [
        "from google.cloud import secretmanager_v1 as secretmanager\n",
        "from google.auth import default as google_auth\n",
        "\n",
        "# Replace the existing import statements\n",
        "import googleapiclient.discovery\n",
        "import googleapiclient.errors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Google Mail reader.\"\"\"\n",
        "import email\n",
        "from typing import Any, List\n",
        "from llama_index.readers.base import BaseReader\n",
        "from llama_index.readers.schema.base import Document\n",
        "from pydantic import BaseModel\n",
        "import base64\n",
        "\n",
        "SCOPES = [\"https://www.googleapis.com/auth/gmail.readonly\"]\n",
        "\n",
        "\n",
        "class GmailReader(BaseReader, BaseModel):\n",
        "    \"\"\"Gmail reader.\n",
        "\n",
        "    Reads emails\n",
        "\n",
        "    Args:\n",
        "        query (str): Gmail query. Defaults to None.\n",
        "        max_results (int): Max number of results. Defaults to 10.\n",
        "    \"\"\"\n",
        "    query: str = None\n",
        "    use_iterative_parser: bool = False\n",
        "    max_results: int = 10\n",
        "    service: Any\n",
        "\n",
        "\n",
        "    def load_data(\n",
        "        self\n",
        "    ) -> List[Document]:\n",
        "        \"\"\"Load emails from the user's account\n",
        "        \"\"\"\n",
        "        from googleapiclient.discovery import build\n",
        "\n",
        "        credentials = self._get_credentials()\n",
        "        import json\n",
        "        from google.oauth2.credentials import Credentials\n",
        "\n",
        "        #credentials is a JSON string\n",
        "        credentials_json = credentials\n",
        "\n",
        "        # Load the JSON string into a dictionary\n",
        "        credentials_dict = json.loads(credentials_json)\n",
        "\n",
        "        #Create Google API credentials object\n",
        "        credentials1 = Credentials.from_authorized_user_info(credentials_dict)\n",
        "\n",
        "\n",
        "        # use authorized credentials object in the build_resource_service function\n",
        "        #api_resource = build_resource_service(credentials = credentials1)\n",
        "\n",
        "        if not self.service:\n",
        "            self.service = build('gmail', 'v1', credentials=credentials1)\n",
        "\n",
        "        messsages = self.search_messages()\n",
        "\n",
        "        results = []\n",
        "        for message in messsages:\n",
        "            text = message.pop('body')\n",
        "            #extra_info = message\n",
        "            #results.append(Document(text, extra_info=extra_info))\n",
        "            results.append(Document(text))\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _get_credentials(self) -> Any:\n",
        "        secret_name = 'token'\n",
        "        project_id = 'vivid-kite-315522'\n",
        "\n",
        "        # Create the Secret Manager client\n",
        "        client = secretmanager.SecretManagerServiceClient()\n",
        "\n",
        "        # Build the secret name path\n",
        "        secret_path = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\"\n",
        "\n",
        "        # Access the secret version\n",
        "        response = client.access_secret_version(request={\"name\": secret_path})\n",
        "\n",
        "        # Retrieve the secret value\n",
        "        secret_value = response.payload.data.decode(\"UTF-8\")\n",
        "\n",
        "        # Use the secret value as your credentials\n",
        "        return secret_value\n",
        "\n",
        "        # Retrieve the credentials from Secret Manager\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def search_messages(self):\n",
        "        query = self.query\n",
        "\n",
        "        max_results = self.max_results\n",
        "\n",
        "        messages = self.service.users().messages().list(\n",
        "            userId='me',\n",
        "            q=query,\n",
        "            maxResults=int(max_results)\n",
        "        ).execute().get('messages', [])\n",
        "\n",
        "        result = []\n",
        "        try:\n",
        "            for message in messages:\n",
        "                message_data = self.get_message_data(message)\n",
        "                if not message_data:\n",
        "                    continue\n",
        "                result.append(message_data)\n",
        "        except Exception as e:\n",
        "            raise Exception(\"Can't get message data\" + str(e))\n",
        "\n",
        "        return result\n",
        "\n",
        "    def get_message_data(self, message):\n",
        "        message_id = message['id']\n",
        "        message_data = self.service.users().messages().get(\n",
        "            format=\"raw\",\n",
        "            userId='me',\n",
        "            id=message_id).execute()\n",
        "        if self.use_iterative_parser:\n",
        "            body = self.extract_message_body_iterative(message_data)\n",
        "        else:\n",
        "            body = self.extract_message_body(message_data)\n",
        "\n",
        "        if not body:\n",
        "            return None\n",
        "\n",
        "        return {\n",
        "            #\"id\": message_data['id'],\n",
        "            #\"threadId\": message_data['threadId'],\n",
        "            #\"snippet\": message_data['snippet'],\n",
        "            \"body\": body,\n",
        "        }\n",
        "\n",
        "    def extract_message_body_iterative(self, message:dict):\n",
        "        if message['raw']:\n",
        "            body = base64.urlsafe_b64decode(message['raw'].encode('utf8'))\n",
        "            mime_msg = email.message_from_bytes(body)\n",
        "        else:\n",
        "            mime_msg = message\n",
        "\n",
        "        body_text = ''\n",
        "        if mime_msg.get_content_type() == 'text/plain':\n",
        "            plain_text = mime_msg.get_payload(decode=True)\n",
        "            charset = mime_msg.get_content_charset('utf-8')\n",
        "            body_text = plain_text.decode(charset).encode('utf-8').decode('utf-8')\n",
        "\n",
        "        elif mime_msg.get_content_maintype() == 'multipart':\n",
        "            msg_parts = mime_msg.get_payload()\n",
        "            for msg_part in msg_parts:\n",
        "                body_text += self.extract_message_body_iterative(msg_part)\n",
        "\n",
        "        return body_text\n",
        "\n",
        "    def extract_message_body(self, message: dict):\n",
        "        from bs4 import BeautifulSoup\n",
        "        try:\n",
        "            body = base64.urlsafe_b64decode(message['raw'].encode('ASCII'))\n",
        "            mime_msg = email.message_from_bytes(body)\n",
        "\n",
        "            # If the message body contains HTML, parse it with BeautifulSoup\n",
        "            if 'text/html' in mime_msg:\n",
        "                soup = BeautifulSoup(body, 'html.parser')\n",
        "                body = soup.get_text()\n",
        "            return body.decode(\"ascii\")\n",
        "        except Exception as e:\n",
        "            raise Exception(\"Can't parse message body\" + str(e))\n",
        "\n"
      ],
      "metadata": {
        "id": "g47sRVSoCXsB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "FzI-ozmHIn-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install InstructorEmbedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58PrDVK6IpPs",
        "outputId": "43f91c4d-b52d-44b1-86a0-3d220cc4d787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting InstructorEmbedding\n",
            "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: InstructorEmbedding\n",
            "Successfully installed InstructorEmbedding-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import openai\n",
        "import os\n",
        "import json\n",
        "\n",
        "from google.cloud import secretmanager\n",
        "\n",
        "# Set up the Secret Manager client\n",
        "client1 = secretmanager.SecretManagerServiceClient()\n",
        "name1 = \"projects/339902708114/secrets/openai_api_key/versions/latest\"\n",
        "response1 = client1.access_secret_version(request={\"name\": name1})\n",
        "\n",
        "# Retrieve the API key from the secret\n",
        "api_key1 = response1.payload.data.decode(\"UTF-8\")\n",
        "\n",
        "# Set the OpenAI API key\n",
        "openai.api_key = api_key1\n",
        "os.environ[\"OPENAI_API_KEY\"]=api_key1\n",
        "\n",
        "from llama_index import VectorStoreIndex\n",
        "from langchain.embeddings.huggingface import HuggingFaceInstructEmbeddings\n",
        "from llama_index import LangchainEmbedding,ServiceContext\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    reader = GmailReader(query=\"from:me after:2023-06-14\")\n",
        "    documents = reader.load_data()\n",
        "    index = VectorStoreIndex.from_documents(documents)\n",
        "\n",
        "    print(index)\n",
        "\n",
        "    query_engine = index.as_query_engine()\n",
        "    response = query_engine.query(\"What is the subject of the recent email\")\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkhbJbP2mF01",
        "outputId": "80841f07-7186-4a06-92eb-8b1fb078ab71"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<llama_index.indices.vector_store.base.VectorStoreIndex object at 0x7f49981c1000>\n",
            "\n",
            "The subject of the recent email is \"Learning LlamaIndex\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another way to save it in vector database and make a query"
      ],
      "metadata": {
        "id": "KcT4PMp5SveO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import secretmanager\n",
        "\n",
        "# Set up the Secret Manager client\n",
        "client1 = secretmanager.SecretManagerServiceClient()\n",
        "name1 = \"projects/339902708114/secrets/openai_api_key/versions/latest\"\n",
        "response1 = client1.access_secret_version(request={\"name\": name1})\n",
        "\n",
        "# Retrieve the API key from the secret\n",
        "api_key1 = response1.payload.data.decode(\"UTF-8\")\n",
        "\n",
        "# Set the OpenAI API key\n",
        "openai.api_key = api_key1\n",
        "os.environ[\"OPENAI_API_KEY\"]=api_key1"
      ],
      "metadata": {
        "id": "m3ubll_lPkn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import json\n",
        "\n",
        "from llama_index import VectorStoreIndex\n",
        "\n",
        "from langchain.embeddings.huggingface import HuggingFaceInstructEmbeddings\n",
        "from llama_index import LangchainEmbedding, ServiceContext, VectorStoreIndex\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create the embedding model\n",
        "    embed_model = LangchainEmbedding(HuggingFaceInstructEmbeddings())\n",
        "\n",
        "    # Create the service context\n",
        "    service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
        "\n",
        "    # Load the documents\n",
        "    reader = GmailReader(query=\"from:me after:2023-06-14\")\n",
        "    documents = reader.load_data()\n",
        "\n",
        "    # Create the vector index\n",
        "    index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "\n",
        "    # Print the index\n",
        "    print(index)\n",
        "    query_engine = index.as_query_engine()\n",
        "    response = query_engine.query(\"What is the subject of the recent email\")\n",
        "    print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egY0XNlfPppe",
        "outputId": "ebb45783-43a2-4056-a39a-343f4c76f23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n",
            "<llama_index.indices.vector_store.base.VectorStoreIndex object at 0x7f474acf5810>\n",
            "\n",
            "The subject of the recent email is \"Learning LlamaIndex\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try if openai works"
      ],
      "metadata": {
        "id": "WWbKCIiuSm1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm= OpenAI(model_name=\"gpt-3.5-turbo\")\n",
        "llm(\"What's 5 to the 8th power\") #simple test query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mW7s0I5RO41m",
        "outputId": "7d635b99-b1c0-4236-ee1f-3d78a02ca32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'39,0625'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FmBWmLzKmNa"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}